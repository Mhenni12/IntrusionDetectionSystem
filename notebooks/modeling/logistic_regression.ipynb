{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../data/KDDTrain+.csv\"\n",
    "test_path = \"../../data/KDDTest+.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"attack_class\"\n",
    "\n",
    "X_train = train_df.drop(columns=[target_col, \"attack\"])\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df.drop(columns=[target_col, \"attack\"])\n",
    "y_test = test_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"protocol_type\", \"service\", \"flag\"]\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    (\"num\", StandardScaler(), numerical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        solver=\"lbfgs\",\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "y_pred = logreg_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6205 1191   61    0    2]\n",
      " [ 416 8878  346   34   37]\n",
      " [ 123  191 2060   41    6]\n",
      " [   3 1801   19  681  381]\n",
      " [   0   17    0   16   34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DoS       0.92      0.83      0.87      7459\n",
      "      Normal       0.74      0.91      0.81      9711\n",
      "       Probe       0.83      0.85      0.84      2421\n",
      "         R2L       0.88      0.24      0.37      2885\n",
      "         U2R       0.07      0.51      0.13        67\n",
      "\n",
      "    accuracy                           0.79     22543\n",
      "   macro avg       0.69      0.67      0.61     22543\n",
      "weighted avg       0.82      0.79      0.78     22543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../models/artifacts\")\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(logreg_pipeline, artifacts_dir / \"logistic.joblib\")\n",
    "\n",
    "# Metadata\n",
    "metadata_path = Path(\"../../models/metadata.json\")\n",
    "metadata = {}\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "metadata[\"LogisticRegression\"] = {\n",
    "    \"model_name\": \"Logistic Regression\",\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"task\": \"Intrusion Detection\",\n",
    "    \"metrics\": report,\n",
    "    \"hyperparameters\": logreg_pipeline.named_steps[\"classifier\"].get_params()\n",
    "}\n",
    "\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project1-venv)",
   "language": "python",
   "name": "project1-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
