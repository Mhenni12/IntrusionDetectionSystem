{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/KDD_reduced.csv\"\n",
    "\n",
    "data_df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"attack_class\"\n",
    "\n",
    "# Drop rows where the target column is NaN\n",
    "data_df_cleaned = data_df.dropna(subset=[target_col])\n",
    "\n",
    "X = data_df_cleaned.drop(columns=[target_col, \"attack\"])\n",
    "y = data_df_cleaned[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"protocol_type\", \"service\", \"flag\"]\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    (\"num\", StandardScaler(), numerical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        solver=\"lbfgs\",\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "y_pred = logreg_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 9009   199    13     0     3]\n",
      " [   65 12462   310   371   178]\n",
      " [    8    29  2327     3     6]\n",
      " [    0     6     0   186     7]\n",
      " [    0     2     0     4     7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DoS       0.99      0.98      0.98      9224\n",
      "      Normal       0.98      0.93      0.96     13386\n",
      "       Probe       0.88      0.98      0.93      2373\n",
      "         R2L       0.33      0.93      0.49       199\n",
      "         U2R       0.03      0.54      0.07        13\n",
      "\n",
      "    accuracy                           0.95     25195\n",
      "   macro avg       0.64      0.87      0.68     25195\n",
      "weighted avg       0.97      0.95      0.96     25195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../models/artifacts\")\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(logreg_pipeline, artifacts_dir / \"logistic.joblib\")\n",
    "\n",
    "# Metadata\n",
    "metadata_path = Path(\"../../models/metadata.json\")\n",
    "metadata = {}\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "metadata[\"LogisticRegression\"] = {\n",
    "    \"model_name\": \"Logistic Regression\",\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"task\": \"Intrusion Detection\",\n",
    "    \"metrics\": report,\n",
    "    \"hyperparameters\": logreg_pipeline.named_steps[\"classifier\"].get_params()\n",
    "}\n",
    "\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:490: FitFailedWarning: \n",
      "45 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 621, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n",
      "    raise ValueError(\n",
      "ValueError: The 'liblinear' solver does not support multiclass classification (n_classes >= 3). Either use another solver or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1137: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.77448855        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__C': np.float64(0.08858667904100823)}\n",
      "\n",
      "Best CV Score:\n",
      "0.7744885546553166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\medaz\\Documents\\IntrusionDetectionSystem\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline for RandomizedSearchCV that includes preprocessing\n",
    "# The preprocessor was defined in cell MhI9Lo4C1IDK\n",
    "\n",
    "log_reg_pipeline_for_search = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter distributions for the classifier step within the pipeline\n",
    "param_dist = {\n",
    "    'classifier__C': np.logspace(-4, 4, 20),      # regularization strength\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Random Search\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=log_reg_pipeline_for_search,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,              # number of combinations\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "random_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\")\n",
    "print(random_search_lr.best_params_)\n",
    "\n",
    "print(\"\\nBest CV Score:\")\n",
    "print(random_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         DoS       0.99      0.97      0.98      9224\n",
      "      Normal       0.97      0.98      0.98     13386\n",
      "       Probe       0.96      0.94      0.95      2373\n",
      "         R2L       0.59      0.58      0.59       199\n",
      "         U2R       0.50      0.31      0.38        13\n",
      "\n",
      "    accuracy                           0.97     25195\n",
      "   macro avg       0.80      0.76      0.78     25195\n",
      "weighted avg       0.97      0.97      0.97     25195\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 8983   236     5     0     0]\n",
      " [   44 13179    82    77     4]\n",
      " [   22   117  2233     1     0]\n",
      " [    1    82     0   116     0]\n",
      " [    1     5     0     3     4]]\n"
     ]
    }
   ],
   "source": [
    "best_lr = random_search_lr.best_estimator_\n",
    "\n",
    "y_pred = best_lr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../models/logreg_model.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/logreg_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_lr, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
